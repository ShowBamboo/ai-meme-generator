"""
è‡ªåŠ¨æ–‡æ¡ˆç”Ÿæˆå™¨
æ ¹æ®è¾“å…¥å’Œé£æ ¼ç»™å‡ºæ›´æœ‰æ¢—çš„çŸ­å¥
å¯é€‰æ¥å…¥å¤–éƒ¨æ¨¡å‹ï¼ˆOpenAI-compatible Chat Completionsï¼‰
"""

import os
import random
import requests
import re


class CaptionGenerator:
    def __init__(self):
        self.templates = [
            "è¿™è°é¡¶å¾—ä½å•Š",
            "æˆ‘çœŸçš„ä¼šè°¢",
            "ä»Šå¤©ä¹Ÿå¤ªç¦»è°±äº†å§",
            "è¡Œå§è¡Œå§æˆ‘æŠ•é™",
            "ç¬‘ä¸æ´»äº†",
            "æˆ‘ä¸ç†è§£ä½†æˆ‘å°Šé‡",
            "æˆ‘çš„æ²‰é»˜éœ‡è€³æ¬²è‹",
            "ä½ ç¤¼è²Œå—",
            "æˆ‘å¤ªéš¾äº†",
            "ä½ è¯´å¾—å¯¹ï¼Œç„¶åå‘¢",
            "è®©å­å¼¹å†é£ä¸€ä¼šå„¿",
        ]

        self.style_bias = {
            "cartoon": ["å¤¸å¼ åˆ°èµ·é£", "å¡é€šæ„Ÿæ‹‰æ»¡"],
            "hand-drawn": ["éšæ‰‹ä¸€ç”»å°±å¾ˆé¡¶", "æ‰‹ç»˜æ„Ÿæ‹¿æ"],
            "anime": ["ä¸­äºŒä¹‹é­‚ç‡ƒäº†", "åŠ¨æ¼«æ„Ÿçˆ†è¡¨"],
            "realistic": ["è¿™ä¹Ÿå¤ªçœŸå®äº†", "ç°å®å‡»ä¸­æˆ‘"],
            "retro": ["å¤å¤æ»¤é•œå¼€æ»¡", "åƒç´ é£yyds"],
            "minimalist": ["æç®€ä½†ä¸ç®€å•", "å°‘å³æ˜¯å¤š"],
        }

        self.meme_addons = [
            "æ‡‚çš„éƒ½æ‡‚",
            "åˆ«é—®ï¼Œé—®å°±æ˜¯",
            "ç¦»è°±ä½†åˆç†",
            "ä¸€æ•´ä¸ªæ— è¯­ä½äº†",
            "æˆ‘çœŸçš„ä¼šæ “Q",
        ]
        self.llm_url = os.getenv("CAPTION_LLM_URL", "").strip()
        self.llm_key = os.getenv("CAPTION_LLM_API_KEY", "").strip()
        self.llm_model = os.getenv("CAPTION_LLM_MODEL", "").strip()
        self.llm_temperature = float(os.getenv("CAPTION_LLM_TEMPERATURE", "0.9"))
        self.llm_timeout = int(os.getenv("CAPTION_LLM_TIMEOUT", "30"))
        self.llm_debug = os.getenv("CAPTION_LLM_DEBUG", "").strip().lower() in {
            "1",
            "true",
            "yes",
            "on",
        }
        if self.llm_url:
            print(f"ğŸ“ Caption LLM enabled: model={self.llm_model or 'default'}")
        else:
            print("ğŸ“ Caption LLM disabled (CAPTION_LLM_URL not set)")

    def generate(self, prompt: str, style: str = "cartoon", meme_mode: bool = False) -> str:
        if self._llm_enabled():
            try:
                captions = self._call_llm(prompt, style, meme_mode, count=1)
                if captions:
                    return captions[0]
            except Exception as e:
                print(f"âš ï¸ Caption LLM failed: {e}")

        base = random.choice(self.templates)
        bias = random.choice(self.style_bias.get(style, [])) if self.style_bias.get(style) else ""
        addon = random.choice(self.meme_addons) if meme_mode else ""

        parts = [base]
        if bias:
            parts.append(bias)
        if addon:
            parts.append(addon)

        # èåˆç”¨æˆ·è¾“å…¥å…³é”®è¯ï¼ˆç®€å•æ‹¼æ¥é¿å…è¿‡é•¿ï¼‰
        keyword = prompt.strip()
        if keyword and len(keyword) <= 8:
            parts.insert(0, keyword)

        return "ï¼Œ".join(parts)

    def generate_batch(
        self, prompt: str, style: str = "cartoon", meme_mode: bool = False, count: int = 3
    ) -> list[str]:
        count = max(1, min(6, int(count)))
        if self._llm_enabled():
            try:
                captions = self._call_llm(prompt, style, meme_mode, count=count)
                if captions:
                    return captions[:count]
            except Exception as e:
                print(f"âš ï¸ Caption LLM failed: {e}")

        results: list[str] = []
        seen = set()
        attempts = 0

        while len(results) < count and attempts < count * 4:
            caption = self.generate(prompt, style, meme_mode)
            attempts += 1
            if caption in seen:
                continue
            seen.add(caption)
            results.append(caption)

        return results

    def _llm_enabled(self) -> bool:
        return bool(self.llm_url)

    def _call_llm(
        self, prompt: str, style: str, meme_mode: bool, count: int = 1
    ) -> list[str]:
        count = max(1, min(6, int(count)))
        headers = {"Content-Type": "application/json"}
        if self.llm_key:
            headers["Authorization"] = f"Bearer {self.llm_key}"

        system = (
            "ä½ æ˜¯ä¸€ä¸ªä¸­æ–‡è¡¨æƒ…åŒ…æ–‡æ¡ˆç”Ÿæˆå™¨ã€‚è¾“å‡ºç®€çŸ­ã€æœ‰æ¢—ã€å£è¯­åŒ–çš„æ–‡æ¡ˆã€‚"
            "ä¸è¦æ·»åŠ å¼•å·ã€ä¸è¦ç¼–å·ã€ä¸è¦è§£é‡Šã€‚"
        )
        user = (
            f"ç”¨æˆ·æç¤ºè¯ï¼š{prompt}\n"
            f"é£æ ¼ï¼š{style}\n"
            f"çƒ­æ¢—æ¨¡å¼ï¼š{'æ˜¯' if meme_mode else 'å¦'}\n"
            f"è¯·è¾“å‡º {count} æ¡æ–‡æ¡ˆï¼Œæ¯æ¡ä¸€è¡Œï¼Œé•¿åº¦<=12å­—ã€‚"
        )

        payload = {
            "model": self.llm_model or "default",
            "messages": [
                {"role": "system", "content": system},
                {"role": "user", "content": user},
            ],
            "temperature": self.llm_temperature,
            "max_tokens": 160,
        }

        response = requests.post(
            self.llm_url, headers=headers, json=payload, timeout=self.llm_timeout
        )
        if response.status_code >= 400:
            body_preview = response.text[:800].replace("\n", " ")
            if self.llm_debug:
                print(f"âŒ Caption LLM HTTP {response.status_code} body: {body_preview}")
        response.raise_for_status()
        data = response.json()

        content = ""
        if isinstance(data, dict):
            choices = data.get("choices") or []
            if choices:
                content = choices[0].get("message", {}).get("content", "")
            if not content:
                output = data.get("output") or {}
                output_choices = output.get("choices") or []
                if output_choices:
                    content = output_choices[0].get("message", {}).get("content", "")
            if not content:
                content = data.get("output_text") or data.get("text") or ""

        if not content:
            raise Exception("Empty LLM response")

        lines = re.split(r"[\r\n]+", content)
        cleaned = []
        for line in lines:
            line = line.strip()
            line = re.sub(r"^[\-\*\d\.\)\s]+", "", line)
            if line:
                cleaned.append(line)

        return cleaned[:count]


caption_generator = CaptionGenerator()
